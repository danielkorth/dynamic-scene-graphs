{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e874528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.data_loading import load_all_color_images, load_all_depth_images, read_trajectory\n",
    "import rerun as rr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ece54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rerun.blueprint as rrb\n",
    "def setup_blueprint():\n",
    "    blueprint = rrb.Blueprint(\n",
    "        rrb.Horizontal(\n",
    "                rrb.Vertical(\n",
    "                    rrb.Spatial3DView(name=\"3D\", origin=\"world\", line_grid=rrb.archetypes.LineGrid3D(plane=rr.components.Plane3D(np.array([0, 0, 1])))),\n",
    "                ),\n",
    "                rrb.Vertical(\n",
    "                    rrb.Spatial2DView(name=\"RGB\", origin=\"world/camera/image\", contents=\"world/camera/image/rgb\"),\n",
    "                    rrb.Spatial2DView(name=\"Depth\", origin=\"world/camera/image\", contents=\"world/camera/image/depth\"),\n",
    "                    rrb.Spatial2DView(name=\"SAM\", origin=\"world/camera/image\", contents=\"world/camera/image/sam\"),\n",
    "                    name=\"2D\",\n",
    "                    row_shares=[1,1,1]\n",
    "                ),\n",
    "            ),\n",
    "    )\n",
    "    return blueprint\n",
    "\n",
    "rr.init(\"something5\", spawn=False, default_blueprint=setup_blueprint())\n",
    "rr.connect_grpc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_PATH = \"/local/home/dkorth/Projects/dynamic-scene-graphs/data/living_room_1/color\"\n",
    "DEPTH_PATH = \"/local/home/dkorth/Projects/dynamic-scene-graphs/data/living_room_1/depth\"\n",
    "TRAJ_PATH = \"/local/home/dkorth/Projects/dynamic-scene-graphs/data/living_room_1/livingroom1-traj.txt\"\n",
    "\n",
    "rgb = load_all_color_images(COLOR_PATH)\n",
    "depth = load_all_depth_images(DEPTH_PATH)\n",
    "traj = read_trajectory(TRAJ_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment import SAM2Segmenter\n",
    "segmenter = SAM2Segmenter(\n",
    "    sam2_checkpoint=\"../checkpoints/sam2.1/sam2.1_hiera_tiny.pt\",\n",
    "    model_cfg=\"configs/sam2.1/sam2.1_hiera_t.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4042af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rerun as rr\n",
    "import seaborn as sns\n",
    "\n",
    "rr.set_time(timeline=\"world/camera/image\", sequence=0)\n",
    "K = np.array([[481.20, 0, 319.50], [0, 480.00, 239.50], [0, 0, 1]])\n",
    "\n",
    "rr.log(\"world/camera/image\", rr.ViewCoordinates.RDF)\n",
    "\n",
    "rr.log(\"world/camera/image\", rr.Pinhole(\n",
    "    resolution=[640, 480],\n",
    "    principal_point=[319.50, 239.50],\n",
    "    focal_length=[481.20, 480.00],\n",
    "))\n",
    "\n",
    "for i, (d, img) in enumerate(zip(depth, rgb[:40])):\n",
    "\n",
    "    # images\n",
    "    rr.log(\"world/camera/image/rgb\", rr.Image(img, color_model=rr.ColorModel.RGB))\n",
    "    rr.log(\"world/camera/image/depth\", rr.DepthImage(d/1000))\n",
    "\n",
    "    # sam masks\n",
    "    masks = segmenter.segment(img)\n",
    "    masks_with_ids = list(enumerate(masks, start=1))\n",
    "    masks_with_ids.sort(key=(lambda x: x[1][\"area\"]), reverse=True)\n",
    "\n",
    "    # Layer all of the masks together, using the id as class-id in the segmentation\n",
    "    segmentation_img = np.zeros((rgb[0].shape[0], rgb[0].shape[1]))\n",
    "    for id, m in masks_with_ids:\n",
    "        segmentation_img[m[\"segmentation\"]] = id\n",
    "    \n",
    "    all_points = []\n",
    "    all_colors = []\n",
    "    points = unproject_depth_to_world_grid(d/1000, K, traj[i].rotation, traj[i].translation)\n",
    "    rr.log(\"points\", rr.Points3D(points.reshape(-1, 3), colors=np.zeros((points.shape[0], 3))))\n",
    "    for color, mask in zip(sns.color_palette(\"husl\", len(masks)), masks):\n",
    "        points_1 = points[mask[\"segmentation\"]]\n",
    "        colors_1 = np.array([color] * len(points_1))\n",
    "        all_points.append(points_1)\n",
    "        all_colors.append(colors_1)\n",
    "\n",
    "    rr.log(\"semantic_points\", rr.Points3D(np.concatenate(all_points), colors=np.concatenate(all_colors)))\n",
    "\n",
    "    rr.log(\"world/camera/image/sam\", rr.SegmentationImage(segmentation_img.astype(np.uint8)))\n",
    "\n",
    "    # camera pose\n",
    "    rr.log(\"world/camera\", rr.Transform3D(\n",
    "        rotation=rr.RotationAxisAngle(axis=traj[i].rotation_axis_angle, angle=np.linalg.norm(traj[i].rotation_axis_angle)),\n",
    "        translation=traj[i].translation\n",
    "    ))\n",
    "\n",
    "    rr.set_time(timeline=\"world/camera/image\", sequence=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.color_palette(\"husl\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b17748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loading import unproject_depth_to_world_grid\n",
    "\n",
    "K = np.array([[481.20, 0, 319.50], [0, 480.00, 239.50], [0, 0, 1]])\n",
    "points = unproject_depth_to_world_grid(depth[0]/1000, K, traj[0].rotation, traj[0].translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3510580",
   "metadata": {},
   "outputs": [],
   "source": [
    "points[masks[3][\"segmentation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31faefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(masks[0][\"segmentation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb43f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c736a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an colors array similar to the masks array\n",
    "points_1 = points[masks[3]['segmentation']]\n",
    "colorss_1 = np.array([[255, 0, 0]] * len(points_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0d776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5716b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.log(\"points\", rr.Points3D(points.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loading import unproject_depth_to_world\n",
    "\n",
    "K = np.array([[481.20, 0, 319.50], [0, 480.00, 239.50], [0, 0, 1]])\n",
    "points = unproject_depth_to_world(depth[0]/1000, K, traj[0].rotation, traj[0].translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad7e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
